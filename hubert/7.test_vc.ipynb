{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchaudio\n",
    "from torch.nn.modules.utils import consume_prefix_in_state_dict_if_present\n",
    "import sys\n",
    "sys.path.insert(0,'/home/nis/tianyi.tan/hubert/')\n",
    "\n",
    "from hubert.model import HubertSoft\n",
    "\n",
    "def load_hubert(checkpoint_path=None, rank=0, device='cuda'):\n",
    "    print(\"### load_hubert\", checkpoint_path, device)\n",
    "    assert checkpoint_path is not None\n",
    "    print(\"### loading checkpoint from: \", checkpoint_path)\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    hubert = HubertSoft().to(device) if device!='cuda' else HubertSoft().to(rank)\n",
    "\n",
    "    checkpoint = checkpoint['hubert'] if checkpoint['hubert'] is not None else checkpoint\n",
    "    consume_prefix_in_state_dict_if_present(checkpoint, \"module.\")\n",
    "\n",
    "    hubert.load_state_dict(checkpoint, strict=True)\n",
    "    hubert.eval().to(device)\n",
    "    return hubert\n",
    "\n",
    "def load_hifigan(checkpoint_path=\"./hifigan/g_00205000\", device='cuda'):\n",
    "    import sys\n",
    "    sys.path.insert(0,'/home/nis/tianyi.tan/wesper-demo')\n",
    "    import hifigan\n",
    "    import json\n",
    "    with open(\"/home/nis/tianyi.tan/hifigan/hifigan/config.json\", \"r\") as f:\n",
    "        config = json.load(f)\n",
    "    config = hifigan.AttrDict(config)\n",
    "    vocoder = hifigan.Generator(config)\n",
    "    print(\"### HiFI-GAN ckpt\", checkpoint_path)\n",
    "    if checkpoint_path.startswith(\"http\"):\n",
    "        ckpt = torch.hub.load_state_dict_from_url(checkpoint_path, map_location=torch.device('cpu')) if device!='cuda' else torch.hub.load_state_dict_from_url(checkpoint_path)\n",
    "    else:\n",
    "        ckpt = torch.load(checkpoint_path, map_location=torch.device('cpu')) if device!='cuda' else torch.load(checkpoint_path)\n",
    "    checkpoint = ckpt['generator']['model']\n",
    "    consume_prefix_in_state_dict_if_present(checkpoint, \"module.\")\n",
    "    vocoder.load_state_dict(checkpoint)\n",
    "    vocoder.eval()\n",
    "    vocoder.remove_weight_norm()\n",
    "    vocoder.to(device)\n",
    "\n",
    "    return vocoder\n",
    "\n",
    "def load_acoustic(checkpoint_path=None, rank=0, device='cuda'):\n",
    "    import sys\n",
    "    sys.path.insert(0,'/home/nis/tianyi.tan/.cache/torch/hub/bshall_acoustic-model_main')\n",
    "    from acoustic import AcousticModel\n",
    "    \n",
    "    print(\"### load_acoustic\", checkpoint_path, device)\n",
    "    assert checkpoint_path is not None\n",
    "    print(\"### loading checkpoint from: \", checkpoint_path)\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    acoustic = AcousticModel(discrete=False).to(device)\n",
    "    \n",
    "    checkpoint = checkpoint['acoustic-model'] if checkpoint['acoustic-model'] is not None else checkpoint\n",
    "    consume_prefix_in_state_dict_if_present(checkpoint, \"module.\")\n",
    "    \n",
    "    acoustic.load_state_dict(checkpoint)\n",
    "    acoustic.eval().to(device)\n",
    "    return acoustic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### load_hubert /home/nis/tianyi.tan/.cache/torch/hub/checkpoints/model-layer12-450000.pt cuda\n",
      "### loading checkpoint from:  /home/nis/tianyi.tan/.cache/torch/hub/checkpoints/model-layer12-450000.pt\n",
      "### load_acoustic /data/ssd0/tianyi.tan/ckpt-acoustic-model/model-best.pt cuda\n",
      "### loading checkpoint from:  /data/ssd0/tianyi.tan/ckpt-acoustic-model/model-best.pt\n",
      "### HiFI-GAN ckpt /data/ssd0/tianyi.tan/ckpt-voc-128/model-best.pt\n",
      "Removing weight norm...\n"
     ]
    }
   ],
   "source": [
    "# Load the content encoder (either hubert_soft or hubert_discrete)\n",
    "hubert = load_hubert(\"/home/nis/tianyi.tan/.cache/torch/hub/checkpoints/model-layer12-450000.pt\")\n",
    "#hubert = load_hubert(\"/data/hdd0/tianyi.tan/hubert/model-best.pt\") #g0\n",
    "#hubert = load_hubert(\"/data/ssd0/tianyi.tan/ckpt-9M/model-best.pt\") #g5\n",
    "#hubert = torch.hub.load(\"bshall/hubert:main\", \"hubert_soft\", trust_repo=True).cuda()\n",
    "\n",
    "\n",
    "# Load the acoustic model (either hubert_soft or hubert_discrete)\n",
    "#acoustic = load_acoustic(\"/home/nis/tianyi.tan/.cache/torch/hub/checkpoints/hubert-soft-0321fd7e.pt\")\n",
    "#acoustic = load_acoustic(\"/data/hdd0/tianyi.tan/acoustic-model/model-best.pt\") #g0\n",
    "acoustic = load_acoustic(\"/data/ssd0/tianyi.tan/ckpt-acoustic-model/model-best.pt\") #g5\n",
    "#acoustic = torch.hub.load(\"bshall/acoustic-model:main\", \"hubert_soft\", trust_repo=True).cuda()\n",
    "\n",
    "# Load the vocoder (either hifigan_hubert_soft or hifigan_hubert_discrete)\n",
    "#hifigan = load_hifigan(\"/home/nis/tianyi.tan/.cache/torch/hub/checkpoints/g_00205000\")\n",
    "hifigan = load_hifigan(\"/data/ssd0/tianyi.tan/ckpt-voc-128/model-best.pt\")\n",
    "#hifigan = torch.hub.load(\"bshall/hifigan:main\", \"hifigan_hubert_soft\", trust_repo=True).cuda()\n",
    "\n",
    "# Load the source audio\n",
    "#source, sr = torchaudio.load(\"sample_whisper.wav\")\n",
    "source, sr = torchaudio.load(\"s000u053w.WAV\")\n",
    "assert sr == 16000\n",
    "source = source.unsqueeze(0).cuda()\n",
    "\n",
    "# Convert to the target speaker\n",
    "with torch.inference_mode():\n",
    "    # Extract speech units\n",
    "    units = hubert.units(source)\n",
    "    # Generate target spectrogram\n",
    "    mel = acoustic.generate(units).transpose(1, 2)\n",
    "    # Generate audio waveform\n",
    "    target = hifigan(mel)\n",
    "\n",
    "import soundfile as sf\n",
    "sf.write('my_out2.wav',target.squeeze().squeeze().cpu(),16000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "w2n",
   "language": "python",
   "name": "w2n"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
